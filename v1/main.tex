\documentclass[11pt,a4paper,headinclude=true,DIV=14,BCOR=8mm,chapterprefix,listof=totoc,twoside,openright,abstracton]{scrbook}

\usepackage[headsepline]{scrpage2}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{float}
\usepackage[intlimits]{amsmath}
% \usepackage{siunitx}
% \usepackage{color}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{appendix}
\usepackage{hyperref}
\usepackage{hyperref}
\usepackage{mathtools}
% \usepackage[style=authoryear]{biblatex}
\usepackage{natbib}
% \usepackage{newtxtext}
% \usepackage{newtxmath}
% \usepackage{harvard}
\setcitestyle{aysep={}} 
\bibliographystyle{apalike}
\usepackage{xr}
\usepackage{wrapfig}
% \bibliographystyle{agsm}
%\usepackage{feynmf}
%\usepackage{tensor}
\usepackage[framemethod=tikz]{mdframed} % for a block of text

\setlength{\parindent}{0pt}
\geometry{a4paper, tmargin=3cm, bmargin=3cm, lmargin=3cm, rmargin=3cm, headheight=3em, headsep=2em, footskip=1cm}

\setcitestyle{citesep={,}}

\newcommand{\todo}[1]{\textcolor{red}{$\blacksquare$ TODO: #1}} 
\newcommand{\red}[1]{\textcolor{red}{#1}} 
\newcommand{\gray}[1]{\textcolor{gray}{#1}} 

\newmdenv[linecolor=cyan,backgroundcolor=cyan!20]{sidenote}


\geometry{a4paper, tmargin=2cm, bmargin=2cm, lmargin=1cm, rmargin=1cm, headheight=2em, headsep=2em, footskip=1cm}

\title{PhD thesis}
\author{Vsevolod Nedora}
\date{today}

\begin{document}
    
    \maketitle

%% --------------- 
%%
%% Theory
%%
%% ---------------

\chapter{General-Relativistic Hydrodynamics}

In this chapter we provide a basic overview of mathematical and physical bases of this thesis. We do not aim to This chapter is structured as follows. \gray{List the content}

%%
%%
%%

\section{Important concepts and notations}
\red{To be shortened or removed}

Here we provide a list of definitions, notations and symbols used in following sections of this chapter. 

We begin with a brief look at \textit{exterior algebra} and differential forms. Differential 1-forms are naturally dual to vector field on a manifold. Pairing is done via the inner product. For example, if $\phi$ and $\psi$ are the $p$-forms and $q$-forms, then their exterior or wedge product is $\phi\wedge\psi$, a $1+1$ form. Generally, a wedge product of a$p$-form and $q$-form is a $(p+q)$-form. The \textit{Exterior derivative}, operator $d$, is a generalization of a differential of a function. For example, if $\phi=fdx^I$ is a simple $k$-form, its exterior derivative $\text{d}\phi$ is a $(k+1)$-form set by taking differential of the coefficient functions as $\text{d}\phi = \sum_{i=1}^n (\partial f / \partial x^i) dx^i \wedge dx^I$ where $f_k=f_k(x^1,...,x^n)$ are functions of all the coordinates. An arbitrary differential form can be reduced to wedge produce of the generic form $ dx_i\wedge dx_j \wedge...\wedge dx_p $. 

Thus, summarizing, if given a manifold $\mathcal{M}$ and two 1-forms on it $\phi$ and $\psi$ Then the wedge product is $(\phi\wedge\psi)(v,w)=\phi(v)\psi(w) - \phi(w)\psi(v)$ for any $v$ and $w$ tangent vectors to $\mathcal{M}$. The central idea in exterior algebra is that the operations are designed to create the permutational antisymmetry. For instance, consider a wedge product acting on tangent vectors $\boldsymbol{u}$ and $\boldsymbol{v}$, as  $\boldsymbol{u}\wedge\boldsymbol{v}$. Then the result is an antisymmetric tensor product that in addition to bilinarity requires antisymmetry, mimicking the behavior of the cross product. 


Introduce, $T_p \mathcal{M}$, a space of tangent vectors, \textit{tangent space}, then the result of $\boldsymbol{v}\wedge\boldsymbol{u}$ does not belong to $T_p \mathcal{M}$. It is called and alternating bi-vector and it is an element of the vector space $\Lambda^2 T_p (\mathcal{M})$ ,that is called -- second exterior power of $T_p \mathcal{M}$. Generally, $\Lambda^k T_p (\mathcal{M})$ is a subspace of $T_p ^k (\mathcal{M})$. 

Differential forms are very useful for calculus independent of coordinates. For example, differential form can be used to define a volume element as $f(x,y,z)dx \wedge dy \wedge dz$. An exterior product $d$ that converts $k$-from into $k+1$-form similar to the divergence and the curl of a vector field. If there are two manifolds, then the albegra of differential forms and their exterior derivatives is preserved by the \textit{pull-black} under the smooth function. This allows geometrically invariant information to be moved from one space to another via the pullback. Similarly a \textit{push-forward} is defined.

A disjoint union of tangent spaces, $T_p$ of a differential manifold $\mathcal{M}$, is called \textit{tangent bundle} $T\mathcal{M}$. Similarly, a \textit{cotangent bundle}, $T^*\mathcal{M}$, is defined. 

Next, consider a smooth manifold, $\mathcal{M}$, equipped with a positive-definite inner product $g_p$ on the tangent space $T_p \mathcal{M}$ at each point $p$, \textit{i.e.,} the \textit{Reimannian manifold}. The family $g_p$ of inner products is called a \textit{Riemannian metric}, and defines a fiber-wise isomorphism of the tangent and cotangent spaces. It allows to convert vector fields to co-vector field and vice versa. It also allows the definition of the \textit{Hodge star operator}, $\star$. To demonstrate how Hodge star works, we consider an example in 3D Euclidean space. Let there be an orientated plane that is presented by the exterior product $\wedge$, of two basis vectors. Then its Hodge dual is the normal vector given by the cross product. 
More generally, let $V$ be a $n$-dimensional vector space with nondegenerate symmetric bilinear form $\langle\cdot,\cdot\rangle$ -- the \textit{inner product}, then, formally, the Hodge star operator is a linear operator on the exterior algebra of $V$, mapping $k$-vectors to $(n-k)$-vectors for $0\leq k \leq n$. It has following property that defines it completely 
$\alpha\wedge(\star\beta) = \langle\alpha,\beta\rangle\omega$ for every pair of $k-$vectors $\alpha\beta\in\Lambda^kV$. 
Here the $\omega\in\Lambda^n V$ is the unit $n-$vector defined in terms of an oriented orthonormal basis $\{e_1,...,e_n\}$ of $V$ as $\omega := e_1 \wedge \cdots \wedge e_n$. 

As another example, consider 2D space with normalized Euclidean metric and orientation given by ordering $(x,y)$, the Hodge star on $k-$forms is given by $\star 1 = dx \wedge dy$, $\star dx = dy$, $\star dy = -dx$ and $ \star(dx \wedge dy) = 1 $. 
Another important example is a 3D case, where the $\star$ can be regarded as a correspondence between vectors and bivectors in Euclidean $\boldsymbol{R}^3$, the basis one-forms then $ \star dx = dy\wedge dz$ , $\star dy = dz\wedge dx$, and $\star dz = dx \wedge dy$. The relation to the exterior and cross products are: $\star(\boldsymbol{u}\wedge\boldsymbol{v})=\boldsymbol{u}\times\boldsymbol{v}$ and $\star(\boldsymbol{u}\times\boldsymbol{v}) = \boldsymbol{u}\wedge\boldsymbol{v}$ respectively.

Formally, for an $n-$dimensional oriented pseudo-Reimannian manifold $\mathcal{M}$ we apply the construction such that to each cotangent vector space $T^* _p \mathcal{M}$ and its exterior powers $\Lambda^k T_p ^* \mathcal{M}$ and hence to all differential $k-$forms $\xi\in\Omega^k(\mathcal{M})=\Gamma(\Lambda^k T^* \mathcal{M})$, the global sections of the bundle $\Lambda^k T^*\mathcal{M}\rightarrow \mathcal{M}$. The Reimannian metric induces inner product on $\Lambda^k T_p ^* \mathcal{M}$ at each point $p\in\mathcal{M}$. We define the Hodge dual of a $k-$form $\xi$ defining $\star\xi$ as a unique $(n-k)$-form satisfying $\eta\wedge\star\xi = \langle\eta,\xi\rangle\omega$ for every $k-$form $\eta$ where $\langle\eta,\xi\rangle$ is a real value function on $\mathcal{M}$ and the volume form $\omega$ is induced by the Reimannian metric.

%%
%%
%%

\section{The Cauchy Problem in General Relativity}

In this section we briefly recall the initial-value formulation of the Einstein equations of general relativity through the following steps. We start by introducing notations and the basics of GR. We summarize the Einstein field equations, derived via the variation of Hilbert Action. Then we continue with how EFE can be split in a set of evolutionary equations and constraints. For that we focus on the Arnowitt, Deser and Misner, or ADM, formalism. In the end we comment on the stability of the ADM equations, on the need for strongly-hyperbolic formulations of the EFE, and on the choice of gauge conditions commonly used to evolve spacetimes with singularities. This overview is based in \cite{Arnowitt:1962hi,Landau:1982dva,Wald:1984,Misner:1973,Baumgarte:2002jm}, which we refer to for more detained discussion.

%%
%%
%%

\subsection{Euler-Lagrange equations}

We start by introducing a real smooth manifold $\mathcal{M}$ and Lorentzian metric $\boldsymbol{g}$ on $\mathcal{M}$ of signature $(-,+,+,+)$. In general relativity these two objects describe space-time $(\mathcal{M},\boldsymbol{g})$. Let us consider Lagrangian field theory on $(\mathcal{M},\boldsymbol{g})$.

Unless specified otherwise, the $\nabla$ denotes the affine connection associated w.ith $\boldsymbol{g}$, the Levi-Civita connection symbol. We adopt the convention that Greek indices lie in $\{0, 1, 2, 3\}$ and low Latin indices $\{1, 2, 3\}$. With $\nabla\boldsymbol{T}$ we indicate the covariant derivative of a tensor $\boldsymbol{T}$ and $\nabla_{\boldsymbol{u}}\boldsymbol{T}$ is the covariant derivative along a given vector field $\boldsymbol{u}$. In this notations, the scalar product of two vectors $\boldsymbol{a}\cdot\boldsymbol{b}:=g_{\mu\nu}a^{\mu}b^{\nu}$ and the action of a linear form $\boldsymbol{\omega}$ on a vector $\boldsymbol{\upsilon}$ is denoted as $\langle\boldsymbol{\omega},\boldsymbol{\upsilon}\rangle=\omega_{\mu}\upsilon^{\mu}$.

Let the $\boldsymbol{\alpha}$ be the totally antisymmetric symbol that expresses through coordinates $x^{\mu}$ as $\boldsymbol{\alpha} = dx^0 \wedge dx^1 \wedge dx^2 \wedge dx^3$, where $\wedge$ denotes exterior product. Then, proper volume pseudo-form of the spacetime is then $\boldsymbol{\varepsilon} = \sqrt{-g}\boldsymbol{\alpha}$, where $g$ denotes the determinant of the spacetime metric.

The action principle of the Lagrangian field theory on the spacetime $(\mathcal{M}; \boldsymbol{g})$ is
\begin{equation}
S(\boldsymbol{q}, \nabla\boldsymbol{q}) = \int_{\mathcal{M}}\boldsymbol{\alpha}\mathcal{L}(\boldsymbol{q}, \nabla\boldsymbol{q}),
\end{equation}
where $\boldsymbol{q}$ are a set of generalized coordinates for the fields described by the theory, $\nabla$ is the Levi-Civita connection, $\mathcal{L}$ is a scalar density of a scalar quantity $\lambda$ as $\lambda(\boldsymbol{q},\nabla\boldsymbol{q})$. 

Varying the action with respect to the $\boldsymbol{q}$
\begin{equation}
\delta S(\boldsymbol{q}, \nabla\boldsymbol{q}) = \delta\int\boldsymbol{\alpha}\mathcal{L}(\boldsymbol{q}, \nabla\boldsymbol{q}) = \int\boldsymbol{\alpha}\Big(\frac{\partial\mathcal{L}}{\partial\boldsymbol{q}}\delta\boldsymbol{q}+\frac{\partial\mathcal{L}}{\partial(\nabla\boldsymbol{q})}\delta\nabla\boldsymbol{q}\Big)
\end{equation}

As $\delta$ and $\nabla$ commute, and partially integrating $\nabla$, we obtain

\begin{equation}
\partial S(\boldsymbol{q}, \nabla\boldsymbol{q}) = \int\boldsymbol{\alpha}\Big(\frac{\mathcal{L}}{\partial\boldsymbol{q}}-\nabla\frac{\partial \mathcal{L}}{\partial(\nabla\boldsymbol{q})}\Big)\delta\boldsymbol{q} + \int_{\mathcal{M}}\boldsymbol{\alpha}\nabla\Big(\frac{\partial\mathcal{L}}{\partial(\nabla\boldsymbol{q})}\delta\boldsymbol{q}\Big)
\end{equation}

The last term is a boundary term and in order to vanish we impose boundary condition. Assume that the fields are defined over only a compact domain. As the choice of $\partial\boldsymbol{q}$ is arbitrary, the $ \partial S(\boldsymbol{q}, \nabla\boldsymbol{q}) = 0 $ and the Euler-Lagrange equations are

\begin{equation}
\frac{\partial \mathcal{L}}{\partial\boldsymbol{q}} - \nabla\Big(\frac{\partial\mathcal{L}}{\partial(\nabla\boldsymbol{q})}\Big) = 0,
\label{eq:theory:eulerlagrange}
\end{equation}

which represent second-order partial differential equation whose solutions are the functions for which a given functional is stationary.

%%
%%
%%

\subsection{The Hilbert Action}

Here we summarize how the Einstein field equations can be obtained naturally via principle of least action, varying the Hilbert Action.

Consider an action that describes the graviatational field via action $S_g$, and a matter field $\mathcal{L}_m$ via action $S_m$. Then, the total action is

\begin{equation}
    S = S_g + S_m = \int\Big(\frac{1}{2\kappa}R+\mathcal{L}_m\Big)\epsilon,
\end{equation}

where $R$ is the Ricci scalar and $\kappa$ is the Einstein's constant. 
The action principle dictates, that $\delta S = 0$  with respect to the inverse metric $g^{\mu\nu}$, \textit{i.e,}

\begin{equation}
0 = \delta S = \int\Bigg[\frac{1}{2\kappa}\Big(\frac{\delta R}{\delta g^{\mu\nu}}+\frac{R}{\sqrt{-g}}\frac{\delta\sqrt{-g}}{\delta g^{\mu\nu}}\Big) + \frac{1}{\sqrt{-g}}\frac{\delta(\sqrt{-g}\mathcal{L}_m)}{\delta g^{\mu\nu}}\Bigg]\delta g^{\mu\nu}\epsilon
\end{equation}

Owing to the arbitrariness of $\delta g^{\mu\nu}$, the integrant must be zero. 

\begin{equation}
\frac{\delta R}{\delta g^{\mu\nu}} + \frac{R}{\sqrt{-g}}\frac{\delta\sqrt{-g}}{\delta g^{\mu\nu}} = -2\kappa\frac{1}{\sqrt{-g}}\frac{\delta(\sqrt{-g}\mathcal{L}_m)}{\delta g^{\mu\nu}} = -\frac{2\kappa}{\sqrt{-g}}\frac{\delta S_m}{\delta g_{\mu\nu}} := \kappa T_{\mu\nu},
\label{eq:theory:action1}
\end{equation}

where $T_{\mu\nu}$ is the the stress-energy tensor associated with matter action $S_m$. 
The computation of $\delta R / \delta g^{\mu\nu}$ and determinant of the metric $\sqrt{-g}$ is somewhat lengthy. For the sake of brevity, we summarize the result as

\begin{equation}
    \frac{\delta R}{\delta g^{\mu\nu}} = R_{\mu\nu}, \hspace{5mm}
    \frac{1}{\sqrt{-g}}\frac{\delta\sqrt{-g}}{\delta g^{\mu\nu}} = -\frac{1}{2}g_{\mu\nu}.
    \label{eq:theory:deltaR_deltagmuny}
\end{equation}

Substituting Eq. \ref{eq:theory:deltaR_deltagmuny} into equation of motion Eq.  \ref{eq:theory:action1} we obtain the Einstein's field equation 

\begin{equation}
R_{\mu\nu} -\frac{1}{2}g_{\mu\nu}R=8\pi T_{\mu\nu},
\label{eq:theory:EFE}
\end{equation}

where in the geometrized unit system, \textit{i.e} $c=G=1$, the $\kappa=8\pi$. Derived by Einstein in 1915, the equation \ref{eq:theory:EFE} relats the local spacetime curvature (expressed by the Einstein tensor $G_{\mu\nu}=R_{\mu\nu} - \frac{1}{2}Rg_{\mu\nu}$) with the local energy and momentum within that spacetime (expressed by the stress–energy tensor, $T_{\mu\nu}$). A particular usefull mental image of this equation was given by John Wheeler in "Geons, Black Holes, and Quantum Foam" \cite{Wheeler:2010}, "Spacetime tells matter how to move; matter tells spacetime how to curve."

%%
%%
%%

\subsection{Hamiltonian Field Theory}
\red{Note that $\boldsymbol{q}$ were used before but not introduced. Fix.}

Let us start by introducing generalized coordinates $\boldsymbol{q}$, their covariant derivatives $\nabla\boldsymbol{q}$, and recall the volume 4-form $\boldsymbol{\alpha}$. In light of the spacetime decomposition discussed below, we explicitly divide the $\boldsymbol{\alpha}$ into the time $dt$ and spatial parts represented by the antisymmetric symbol ${^{(3)}\boldsymbol{\alpha}}$ as $\boldsymbol{\alpha} = dt \wedge {^{(3)}\boldsymbol{\alpha}}$. Let the "time derivative" be represented by Lie derivative along the vector field $\vec{t}$ as $\dot{\boldsymbol{q}} := \mathcal{L}_{\vec{t}}\:\boldsymbol{q}$. Then, for Lagrangian density, $\Lambda(\boldsymbol{q}, \nabla\boldsymbol{q})$, the conjugate momentum can be written as $\boldsymbol{p} := \partial\Lambda / \partial\dot{\boldsymbol{q}}$. Assuming that $\boldsymbol{p}$ and $\nabla\boldsymbol{q}$ can be expressed as a function of $\boldsymbol{q}$ and $\boldsymbol{p}$ we introduce the Hamiltonian as an integral of its density, and a quantity $J$ as its time integral

\begin{align}
H &= \int_{\Sigma}\mathcal{H}(\boldsymbol{q},\boldsymbol{p}){^{(3)}\boldsymbol{\alpha}} = \int_{\Sigma}{^{(3)}\boldsymbol{\alpha}}\big(\boldsymbol{p}\cdot\dot{\boldsymbol{q}} - \mathcal{L}(\boldsymbol{q}, \nabla\boldsymbol{q})\big), \\
J &= \int_{0}^{t}H(\boldsymbol{q},\boldsymbol{p})dt = \int_{0}^{t}dt\int_{\Sigma}\mathcal{H}(\boldsymbol{q},\boldsymbol{p}){^{(3)}\boldsymbol{\alpha}} = \int_{0}^{t}dt\int_{\Sigma}{^{(3)}\boldsymbol{\alpha}}\Big(\boldsymbol{p}\cdot\dot{\boldsymbol{q}} - \mathcal{L}(\boldsymbol{q},\nabla\boldsymbol{q})\Big).
\end{align}

Consider the variation of the $J$ with respect to the $\delta\boldsymbol{p}$ and $\delta\boldsymbol{q}$ as

\begin{align}
\delta J = \int_{0}^{t}\delta H(\boldsymbol{q},\boldsymbol{p})dt &= \int_{0}^{t}dt (\dot{\boldsymbol{q}}\delta\boldsymbol{p}+\boldsymbol{p}\delta\dot{\boldsymbol{q}}) - \int_{0}^{t}dt\delta\Lambda(\boldsymbol{q}, \nabla\boldsymbol{q}).\\
\delta\Lambda &= \int_{\Sigma}{^{(3)}\boldsymbol{\alpha}}\Bigg[\frac{\delta\Lambda}{\delta\dot{\boldsymbol{q}}}\delta\dot{\boldsymbol{q}}+\frac{\delta\Lambda}{\delta\boldsymbol{q}}\delta\boldsymbol{q}\Bigg] = 
\int_{\Sigma}{^{(3)}\boldsymbol{\alpha}}(\boldsymbol{p}\delta\dot{\boldsymbol{q}} + \dot{\boldsymbol{p}}\delta\boldsymbol{q}),\\
\delta J = \int_{0}^{t} \delta H(\boldsymbol{q},\boldsymbol{p})dt &=  
\int_{0}^{t}dt\Bigg[ \frac{\delta H}{\delta \boldsymbol{p}}\delta \boldsymbol{p} + \frac{\delta H}{\delta \boldsymbol{q}}\delta \boldsymbol{q} \Bigg] =
\int_{0}^{t}dt\int_{\Sigma}{^{(3)}\boldsymbol{\alpha}}(\dot{\boldsymbol{q}}\cdot\delta\boldsymbol{p}-\dot{\boldsymbol{p}}\cdot\delta\boldsymbol{q}),
\end{align}

where first we explicitly written the variation of the Lagrangian, then, we expressed the first term in square brackets as  $\boldsymbol{p}\delta\dot{\boldsymbol{q}}$ using the definition of the conjugate momentum. The second term we transformed applying the Euler-Lagrange equations (\ref{eq:theory:eulerlagrange}). Lastly, we inserted $\delta\Lambda$ back into $\delta J$, that cancelled the term $\boldsymbol{p}\delta\dot{\boldsymbol{q}}$. Then, comparing the result with general $\delta H$, we make use of arbitrariness of  $\delta\boldsymbol{p}$ and $\delta\boldsymbol{p}$ and obtain the Hamilton equations read

\begin{equation}
\dot{\boldsymbol{q}}=\frac{\delta H}{\delta\boldsymbol{p}}, \hspace{5mm} \dot{\boldsymbol{p}} = -\frac{\delta H}{\delta\boldsymbol{q}}.
\label{eq:theory:hamiltoneqs}
\end{equation}

The Hamiltonian formalism can be used to redirive the field-equations in a from that once the initial data is specified on a hypersurface $\Sigma_0$ for $\boldsymbol{q}$ and $\boldsymbol{p}$, the equations (\ref{eq:theory:hamiltoneqs}) would govern whole the evolution.

%%
%%
%%

\subsection{3+1 Decomposition of Einstein field equations}

The Einstein field equations (\ref{eq:theory:EFE}) represent a set of 10 non-linear partial differential equations. They can be defined on an entire metric $\mathcal{M}$ or a given domain $\Omega\subset\mathcal{M}$. In the latter case, the boundary conditions on $\partial\Omega$ are required. 

A widely adopted approach to solving EFE numerically, is to first represent them as a set of evolutionary equations, where spatial properties are evolved in time, \textit{i.e.,} perform a foliation. Geometrically, this is equivalent to representing space-time as a set of spatial slices (space-like hypersurfaces $\Sigma_t$), separated by a timestep, $t$.  This, however, requires the spacetime to be strongly hyperbolic, \textit{i.e.,} $\mathcal{M}=\Sigma\times\mathbb{R}$. In this subsection we summarize the foliation procedure and resulting equation. 

Let the $t$ be the global smooth functions such that, $ \Sigma_{\tau} = \{x^{\alpha}\in\mathcal{M}: t(x^{\alpha})=\tau\} $ and let $\vec{t}$ be a vector such that $\langle\nabla t, \vec{t}\:\rangle = 1$. Thus, $t$ can be seen as a "function that advances time" and $\vec{t}$ as a "flow of time" vector field. Continuing the analogy, the Lie derivative of the $\boldsymbol{q}$ along the vector $\vec{t}$ can be seen as a rate at which a given tensor quantity $\boldsymbol{q}$ changes between hypersurfaces $\Sigma_t$. 

Let us now consider two hypersurfaces $\Sigma_t$ and $\Sigma_{t+dt}$. A transition from one to another can be decomposed into the part tangent to the hypersurface $\Sigma_{t+dt}$ and expressed in a form of a vector $\vec{\beta}$, and a part normal to the hypersurface $\Sigma_t$, and expressed as a $\alpha \vec{n}$, where $\vec{n}$ is a unit vector, normal to the $\Sigma_t$ in the direction to $\Sigma_{t+dt}$. Then, the vector $\vec{t}$ equates to $\vec{t} = \alpha\vec{n}+\vec{\beta}$, where $\vec{\beta}$ is called \textit{shift vector} and $\alpha$ is -- \textit{lapse-function}. In the  spacetime metric $\boldsymbol{g}$ a spatial part, Riemannian metric $\boldsymbol{\gamma}$ can be expressed as $\boldsymbol{\gamma} = \boldsymbol{g} + \underline{n} \otimes \underline{n} $, where $\underline{n}$ is the 1-form associated to the vector $\vec{n}$. The Levi-Civita connection can be computed by projecting the operator $\nabla$ on the space tangent to the hypersurface $\Sigma_t$.

In order to simplify the following expressions, we employ coordinates that are adapted to the foliation, namely $\{t, x^i\}$ with $\vec{\partial}_i\cdot \vec{n} = 0$. In these coordiantes the $\nabla t = dt$ and $\vec{t} = \vec{\partial}_t$. Then, the connection between $\boldsymbol{g}$ and $\boldsymbol{\gamma}$ is $g_{\mu\nu}=\vec{\partial}_{\mu}\cdot\vec{\partial}_{\nu} $ and can be expressed in terms of $\alpha$ and $\vec{\beta}$ as following.

\begin{align*}
\text{Spatial components: } g_{ik}&=\vec{\partial}_{i}\cdot\vec{\partial}_{j} =\gamma_{ik}, \\
\text{time component: } g_{tt} &= \vec{\partial}_{t}\cdot\vec{\partial}_{t} = \vec{t}\cdot\vec{t} = - (\alpha^2-\vec{\beta}\cdot\vec{\beta}), \\
\text{mixed components: } g_{ti} &= \vec{\partial}_{t}\cdot\vec{\partial}_{i} = \vec{t}\cdot\vec{\partial}_i = (\alpha\vec{n}+\vec{\beta})\cdot\vec{\partial}_i=\beta_i, \\
\text{and the line segment: }ds^2 &= -(\alpha^2-\beta_i\beta^i)dt^2 +2\beta_i dx^i dt + \gamma_{ik} dx^i dx^k.
\end{align*}

where we made use of $\vec{\beta}$ being the spatial vector, \textit{i.e} $\vec{\beta}\cdot\vec{\beta}=\gamma_{ik}\beta^i\beta^k$.

%% Extrinsic Curvature and Constraint equations

Next, let us introduce the \textit{extrinsic curvature} of a $D-1$-suface $\Sigma_t\subset\mathcal{M}$ at a point $\mathcal{P}\in\Sigma_t$ as mapping $\boldsymbol{K}$ such that $\boldsymbol{K}(\boldsymbol{\upsilon}) = -\nabla_{\boldsymbol{\upsilon}}\boldsymbol{n}$. Notably, the $\boldsymbol{K}$ thus does not depend on $\alpha$ and $\vec{\beta}$, it is a purely spatial tensor. The components of the extrinsic curvature are

\begin{equation}
K_{\mu\nu} = -{\gamma^{\alpha}}_{\mu}\nabla_{\boldsymbol{u}}^{\alpha} n_{\nu} = -\frac{1}{2}\mathcal{L}_{\vec{n}}\gamma_{\mu\nu},
\label{eq:theory:extrcurvdef}
\end{equation}

where $\mathcal{L}_{\vec{n}}$ is the Lie derivative along the vector field $\vec{n}$. 

The equation (\ref{eq:theory:extrcurvdef}) suggests the following interpretation of the  extrinsic curvature as a "speed of the $\vec{n}$ during the parallel transport along the hypersurface $\Sigma_t$". The extrinsic curvature $K_{\mu\nu}$ can be related to the 4D Ricci tensor $R_{\mu\nu}$ through the Codazzi equation, while $3D$ Riemann tensor $^3{R_{\alpha\beta\gamma}}^{\delta}$ is related to the $4D$ one and the $\boldsymbol{K}$ via Gauss equation,

\begin{align}
D_{\beta}K-D_{\alpha}{K^{\alpha}}_{\beta} &= R_{\gamma\delta}n^{\delta}{\gamma^{\gamma}}_{\beta},\\
^3{R_{\alpha\beta\gamma}}^{\delta} &= {\gamma^{\mu}}_{\alpha}{\gamma^{\nu}}_{\beta}{\gamma^{\lambda}}_{\gamma}{\gamma^{\delta}}_{\sigma}{R_{\mu\nu\lambda}}^{\delta}-K_{\alpha\gamma}{K_{\beta}}^{\delta}+K_{\beta\gamma}{K^{\delta}}_{\alpha}.
\label{eq:theory:formomentum}
%\label{eq:theory:forhamiltconst}
\end{align}

respectively, where $K$ is a trace of the tensor $\boldsymbol{K}$. 

Now, substituting the (\ref{eq:theory:EFE}) into the Codazzi equation and Gauss equation (\ref{eq:theory:formomentum}) we obtain the so-called \textit{momentum constraint} and \textit{momentum constraint}

\begin{align}
    D_{\beta}K-D_{\alpha}{K^{\alpha}}_{\beta} &= -8\pi{\gamma^{\alpha}}_{\beta} n^{\gamma}T_{\alpha\gamma}=:8\pi j_{\beta}, \\
    ^3 R+ K^2 - K_{\alpha\beta}K^{\alpha\beta} &= 2G^{\alpha\beta}n_{\alpha}n_{\beta} = 16\pi n_{\alpha}n_{\beta} T^{\alpha\beta} =: 16\pi E,
    \label{eq:theory:momconstraint}
    %\label{eq:theory:hamilconstraint}
\end{align}

where $E$ is called an ADM energy density. 

The constraint equations (\ref{eq:theory:momconstraint}) represent a set of elliptic equations that must be satisfied on every hyprsurface $\Sigma_i$ of the foliation. It is however, possible to show that Einstein equations preserve the constraints, meaning that if they are satisfied at the initial slice $\Sigma_0$ it will remain so throughout the evolution. 

%% The Hamiltonian Formulation of the Einstein Equations

Next, we briefly sketch a path to derivation the Einstein field equations in the Hamiltonian formalism. For the sake of brevity we shall elude most of the intermediate and computationally extensive steps, as well as the discussion on boundary terms. For that we refer to \cite{Poisson:2004}.

First it is useful to note that determinant of the three-metric $\sqrt{\gamma}$ can be expressed as $\sqrt{\gamma}=\sqrt{-g}/\alpha$. The $p$ is the trace of the canonical momentum $\boldsymbol{p}$.

We start by recalling the EFE (\ref{eq:theory:EFE}) and introduce there the scalar curvature $R$. For that we applying Hamiltinian constraint \ref{eq:theory:hamiltoneqs}. This yields

\begin{align}
G_{\mu\nu} &= R_{\mu\nu} - \frac{1}{2}Rg_{\mu\nu} \\
2(G_{\mu\nu}n^{\mu}n^{\nu} - R_{\mu\nu}n^{\mu}n^{\nu}) &= -Rg_{\mu\nu}n^{\nu}n^{\mu} = -Rn_{\mu}n^{\mu} =  
R.
\label{eq:theory:efe:for_r}
\end{align}

Let us now consider the $R_{\mu\nu}n^{\mu}n^{\nu}$. It can be expressed as a combination of extrinsic curvature and total divergences as following

\begin{align}
R_{\mu\nu}n^{\mu}n^{\nu} &= -(\nabla_{\mu}\nabla_{\gamma} - \nabla_{\gamma}\nabla_{\mu})n^{\gamma}n^{\nu} \\
&= K^2 - K_{\mu\gamma}K^{\mu\gamma} - \nabla_{\mu}(n^{\mu}\nabla_{\gamma}n^{\gamma}) + \nabla_{\gamma}(n^{\mu}\nabla_{\mu}n^{\gamma}) \\
R_{\mu\nu}n^{\mu}n^{\nu} &= K^2 - K_{\mu\nu}K^{\mu\nu}.
\label{eq:theory:rmunu_as_func_k}
\end{align}

where in the last step, we assumed that the variations with compact support, that cancels the last two terms in the total divergences. 

Now, we write Lagrangian density in terms of the variables on the hypersurface, $\Lambda = \sqrt{-g}R $. For that we make use of the fact that  $\sqrt{\gamma}=\sqrt{-g}/\alpha$, and express $R$ via eq. \ref{eq:theory:efe:for_r}, in which $G_{\mu\nu}n^{\mu}n^{\nu}$ we express via the Hamiltonian constraint \ref{eq:theory:hamiltoneqs} and $R_{\mu\nu}n^{\mu}n^{\nu}$ via equation \ref{eq:theory:rmunu_as_func_k} as

\begin{align}
\Lambda &= \sqrt{-g}R = \alpha\sqrt{\gamma}R 
= 2\alpha\sqrt{\gamma}(G_{\mu\nu}n^{\mu}n^{\nu} - R_{\mu\nu}n^{\mu}n^{\nu})\\ 
&= 2\alpha\sqrt{\gamma}\Bigg(\frac{1}{2}\Big[{^{(3)}R} - K_{\mu\nu}K^{\mu\nu} + K^2 \Big] - K^2 - K_{\mu\nu}K^{\mu\nu}\Bigg) \\
\Lambda &= \Lambda_g+\Lambda_m= \frac{1}{16\pi}\alpha\Big({^{(3)}R} + K_{\mu\nu}K^{\mu\nu} - K^2\Big)\sqrt{\gamma}+\Lambda_m
\end{align}

where in the last expression we added a contribution from the matter fields.

Next we note that the extrinsic curvature of a
surface $\Sigma$ is defined as $K_{\mu\nu} = \nabla_{\mu}n_{\nu}$. To relate $K_{\mu\nu}$ to the metric, we make use of the following property of Lie derivatives:

\begin{align}
\mathcal{L}_{\vec{n}}g_{\mu\nu} &= n^{\gamma}\nabla_{\gamma}g_{\mu\nu} + g_{\gamma\nu}\nabla_{\mu}\upsilon^{\gamma} + g_{\mu\gamma}\nabla_{\nu}\upsilon^{\gamma} \\
&= \nabla_{\mu}n_{\nu}+\nabla_{\nu}\upsilon_{\nu} =2\nabla_{\mu}n_{\nu}
\end{align}

where the second expression after "=" holds when $\nabla_{\gamma}\mu$ is the natural derivative operator corresponding to the metric $g_{\mu\nu}$, and the last holds because $K_{\mu\nu}$ is symmetric.

Substituting this into our definition of $K_{\mu\nu}$ (\ref{eq:theory:extrcurvdef}),

\begin{align}
K_{\mu\nu} 
&= -\frac{1}{2}\mathcal{L}_{\vec{n}\:}\gamma_{\mu\nu} \\
&= -\frac{1}{2}[n^{\gamma}\nabla_{\gamma}\gamma_{\mu\nu} + \gamma_{\gamma\nu}\nabla_{\mu}\upsilon^{\nu} + h_{\mu\gamma}\nabla_{\nu}\upsilon^{\gamma}] \\
&= -\frac{1}{2\alpha}{\gamma_{\mu}}^{\gamma}{\gamma_{\nu}}^{\delta}[\partial_t\gamma_{\mu\nu}-D_{\mu}\beta_{\nu}-D_{\nu}\beta_{\mu}] \\
K_{\mu\nu} &= -\frac{1}{2\alpha}(\partial_t\gamma_{\mu\nu}-D_{\mu}\beta_{\nu}-D_{\nu}\beta_{\mu})
\label{eq:theory:3+1:k_mu_nu}
\end{align}

where in the last line we made use of the fact that  projection operators on the hypersurface $\Sigma$ are not needed.

The relation \ref{eq:theory:3+1:k_mu_nu} we use to write the canonical momentum $p^{\mu\nu}$ as

\begin{align}
p^{\mu\nu} &= \frac{\partial\Lambda}{\partial\dot{\gamma}_{\mu\nu}} 
= -\frac{\sqrt{\gamma}}{16\pi}\alpha\Bigg[\frac{\partial {^{(3)}R}}{\partial\dot{\gamma}_{\mu\nu}} + \frac{\partial(K_{\mu\nu}K^{\mu\nu})}{\partial\dot{\gamma}_{\mu\nu}} - \frac{\partial K^2}{\partial\dot{\gamma}_{\mu\nu}}\Bigg] 
= \frac{\sqrt{\gamma}}{16\pi}(K\gamma^{\mu\nu} - K^{\mu\nu}),
\end{align}

where 

\begin{equation}
\frac{\partial K_{\mu\nu}}{\partial \dot{\gamma}_{\mu\nu}} = \frac{1}{2\alpha}, \hspace{5mm} \frac{\partial {^{(3)}R}}{\partial \dot{\gamma}_{\mu\nu}} = 0, \hspace{5mm}\frac{\partial K^2}{\partial \dot{\gamma}_{\mu\nu}} = \frac{\gamma^{\mu\nu}K}{\alpha}
\end{equation}

assuming that there is no explicit dependency of the $\Lambda$ on $\dot{\gamma}_{\mu\nu}$.

Note, that lapse function, $\alpha$, and shift vector, $\vec{\beta}$, are related to the the gauge freedom. This constitutes the freedom in how the manifold $\mathcal{M}$ can be split into hypersurfaces. In addition, as this choice is arbitatry, the momenta associated with these function and vector is zero, and the Hamiltonian density then reads

\begin{align}
\mathcal{H} &= p^{\mu\nu}\dot{\gamma}_{\mu\nu} - \Lambda = -\sqrt{\gamma}\alpha{^{(3)}R} + \frac{\alpha}{\sqrt{\gamma}}\Big[p^{\mu\nu}p_{\mu\nu}-\frac{1}{2}p^2\Big] + 2p^{\mu\nu} D_{\mu}\beta_{\mu} -\Lambda_m \\
%    &=  \frac{\sqrt{\gamma}}{16\pi}\Bigg\{\alpha\Big[-{^{(3)}R}+h^{-1}p^{\mu\nu}p_{\mu\nu}-\frac{1}{2}h^{-1}p^2\Big] - 2\beta_{\nu}\big[D_{\mu}(h^{-1/2}p^{\mu\nu})\big] + D_{\mu}(h^{-1/2}\beta_{\nu}p^{\mu\nu})\Bigg\} \\
&= \frac{\sqrt{\gamma}}{16\pi}\Bigg\{\alpha\Big[ -{^{(3)}R} + \gamma^{-1}p^{\mu\nu}p_{\mu\nu}-\frac{1}{2}\gamma^{-1}p^2\Big] +  2\beta_{\nu}\Big[D_{\mu}(\gamma^{-1/2}p^{\mu\nu})\Big] - 2D_{\mu}(\gamma^{-1/2}\beta_{\nu}p^{\mu\nu}) \Bigg\} - \Lambda_m,
\end{align}

where $p$ is the trace of $\boldsymbol{p}$. In the last line we have restored the correct $16\pi$ factor. Notably, in the case of variations with compact support, the last term (in the brackets), a boundary term, can be neglected. 

The gauge freedom allows to set to zero the variation of $\mathcal{H}$ with respect to $\delta \alpha$ and $\delta \beta_{\mu}$. First, let us consider the matter part of the Hamiltonian $\mathcal{H}$, \textit{i.e,} $\Lambda_m$. The variation of the matter action $S_m$ with respect to the $\alpha$ and $\vec{\beta}$ read

\begin{align}
\frac{\delta S_m}{\delta \alpha} &=-\alpha\frac{\delta S_m}{\delta g_{00}} = -\alpha\sqrt{-g}T^{00} = -\alpha^2\sqrt{\gamma}T^{00} = -\sqrt{\gamma}T^{\mu\nu}n_{\mu}n_{\nu} \\
\frac{\delta S_m}{\delta \beta_{\mu}} &= \frac{\delta S_m}{\delta g_{\mu 0}} =\frac{1}{2}\sqrt{-g}T^{\mu 0} = -\frac{1}{2} \sqrt{\gamma}T^{\mu\nu}n_{\nu}.
\end{align}

Then, the variation of the whole Hamiltonian $H$ with respect to a quantity with vanishing canonical momentum is zero, we obtain two equations 

\begin{align}
\frac{\delta H}{\delta \alpha} &= 0 = -{^{(3)}R} + \gamma^{-1}p^{\mu\nu}p_{\mu\nu}-\frac{1}{2}\gamma^{-1}p^2 + 16\pi T^{\mu\nu}n_{\mu}n_{\nu} \\
\frac{\delta H}{\delta \beta_{\mu}} &= 0 = - D_{\mu}(\gamma^{-1/2}p^{\mu\nu}) + 8\pi{\gamma^{\mu}}_{\nu}n_{\gamma}T^{\nu\gamma}.
\label{eq:theory:hamiltonianvariation}
\end{align}

\red{it might be too high for me} It is important to note, that the $\delta H / \delta\beta_{\mu}$ is actually a Frech\'{e}t differential $dH$, $\delta \beta_{\mu}$, which is writes as

\begin{equation}
\langle dH,\delta\beta \rangle = \delta\beta_{\mu}\big[-D_{\nu}(\gamma^{-1/2}p^{\mu\nu})+8\pi n_{\gamma}T^{\mu\nu}\big], 
\end{equation}

containing $\delta\beta_{\mu}$ which is spatial. Thus only the spatial part is being constrained in the equation above. To account for that the projector ${\gamma^{\mu}}_{\nu}$ is added to the $\delta H/\delta \beta_{\mu}$.

Proceeding with the Hamiltonian formalism we note that Hamilton equations \ref{eq:theory:hamiltoneqs} leads to the evolution equations for the three-metric, assuming that $\Lambda$ explicitly does not depend on the momentum

\begin{equation}
\dot{\gamma}_{\mu\nu} =\frac{\delta H}{\delta p^{\mu\nu}} = 2\gamma^{-1/2}\alpha\big(p_{\mu\nu}-\frac{1}{2}\gamma_{\mu\nu}p\big) - D_{\nu}\beta_{\mu}-D_{\mu}\beta_{\nu}
%    -2D_{(\mu}\beta_{\nu)},
\label{eq:theory:_adm_metric_evo}
\end{equation}

and to the evolution equations for the canonical momentum 

\begin{align}
\dot{p}^{\mu\nu} = -\frac{\delta H}{\delta \gamma_{\mu\nu}} = &+ \alpha\gamma^{1/2}\Big({^{(3)}R}^{\mu\nu}-\frac{1}{2}{^{(3)}R\gamma^{\mu\nu}}\Big) 
 - \frac{1}{2}\alpha\gamma^{-1/2}\gamma^{\mu\nu}\Big(p_{\gamma\delta}p^{\gamma\delta}-\frac{1}{2}p^2\Big) \\
& + 2\alpha\gamma^{-1/2}\big(p^{\mu\gamma}{p^{\nu}}_{\gamma}-\frac{1}{2}pp^{\mu\nu}\big) 
 - \gamma^{1/2}\big(D^{\mu}D^{\nu}\alpha-\gamma^{\mu\nu}D^{\gamma}D_{\gamma}\alpha\big) \\
& - \gamma^{1/2}D_{\gamma}\big(\gamma^{-1/2}\beta^{\gamma}p^{\mu\nu}\big) 
+ 2p^{\gamma(\mu}D_{\gamma}\beta^{\nu)} + 8\pi \alpha \gamma^{1/2}S^{\mu\nu},
\label{eq:theory:_adm_mom_evo}
\end{align}

where $A_{(\mu\nu)} = 0.5(A_{\mu\nu}+A_{\nu\mu})$ the convention was used, and $S^{\mu\nu} = {\gamma^{\mu}}_{\alpha}{\gamma^{\nu}}_{\beta}T^{\alpha\beta}$ and in taking the variation of the matter field the following was used

\begin{equation}
\frac{\delta S}{\delta \gamma_{ik}} = \frac{\delta S_m}{\delta g_{ik}} = \frac{1}{2}\sqrt{-g}T^{ik}
\end{equation}

The set of equations (\ref{eq:theory:hamiltonianvariation}), (\ref{eq:theory:_adm_metric_evo}) and (\ref{eq:theory:_adm_mom_evo}) comprise the ADM system. A more widely used from of these equations is in turns of $\gamma_{ij}$ and $K_{ij}$ that reads

\begin{align}
(\partial_t - \mathcal{L}_{\vec{\beta}})\gamma_{ik} =& -2\alpha K_{ik}; \\
(\partial_t - \mathcal{L}_{\vec{\beta}})K_{ik} =& -D_{i}D_{k}\alpha + \alpha\big(R_{ik} - 2K_{ij}{K^j}_k+KK_{ik}\big) \\
&- 8\pi\alpha\Big(S_{ik} - \frac{1}{2}\gamma_{ik}(S-E)\Big); \\
{^{(3)}R} + K^2 - K_{ik}K^{ik} =& 16\pi E; \\
D_{i}K-D_{k}{K^k}_i =& 8\pi j_i,
\label{eq:theory:adm}
\end{align}

where $S = \gamma^{ij}S_{ij}$.

These equations constitute the IVP for Einstein field equations and are known as ADM equations. The last two equations are the constraint equations. They determine how to set the initial data on the hypersurface $\Sigma_0$, via prescribing the three-metric and extrinsic curvature. The first two equations then govern the evolution.

\todo{make sure that the coefficients in formuals are consistent, $16\pi$ might me missing or $-$}
\todo{Makse sure that $\Lambda$ stands for largangian density and $\mathcal{L}$ for lie derivative}

\subsubsection{The CCZ4 Formulation}


%%
%%
%%

\chapter{Numerical Approximation of Conservation Laws}
\label{ch:nummethods}

Laws of conservation form a foundation of physics. Their complex matematical from, however, makes them challanging ti treat numerically. Thus, approximations are required. In this chapter we briefly outline high-order, state-of-the-art numerical methods for the solution of conservation laws. Owing to their key importance in physics, the amount of literature concerning the topic is extensive. Thus, we shall limit our discussion to what is relevant to this thesis, whilst keep the discussion brief. \gray{A particular focus will be set on general-relativistic hydrodynamics} \\

This chapter is organized as following. \gray{In section ... ... ... }

\section{Theoretical Background}
\label{sec:theory:conserv_laws:theorback}

In this section we outline the mathematical theory of conservation laws, and then, techniques of how they can be implemented numerically. Of particular importance, stand topics of weak and entropic solution for conservation laws, their existance and uniqueness. With respect to the numerical applications, we discuss the consistency, stability and convergence, as well as Lax-Richtmeyer theorem. We conclude with a brief overview of the case of non-linear equations. The brief discusstion that we provide here is based on the fundamental works by \cite{LeVeque:1992} and \cite{Tadmor1998}. We refer to them for more in-depth discussion. 

\subsection{Conservation Laws}

If we consider a basic form of conservation laws, 

%% eq 2.1 and 2.2 in the SOURCE 
\begin{align} 
\partial_t\boldsymbol{u} + \nabla\cdot\boldsymbol{f}(\boldsymbol{u}) = 0, \hspace{10mm} &(t,x)\in \text{I\!R}_{+}\times\text{I\!R}^d , \\
\boldsymbol{u}(0, x) = \boldsymbol{u}(x), \hspace{18mm} &x\in \text{ I\!R},
\label{eq:theory:conservlaws}
\end{align}

where $\boldsymbol{u}$ is the vector of $m$ unknowns, $\boldsymbol{f}=(\boldsymbol{\boldsymbol{f}^1,...,\boldsymbol{f}^m})$ is a $d$-dimensional flux and $\boldsymbol{u_0}\in\big[L^{\infty}(\text{I\!R}^d)\big]^m$ is the initial data. 

It can be shown that the solution of the system \ref{eq:theory:conservlaws} can exhibit discontinuities (shocks) even if the initial data is smooth. Thus, a common approach is to view such a system on the notion of distributions. 

A solution that satisfies an equation \ref{eq:theory:conservlaws} in a prescribed sense, for which, however, not all the derivatives exists, is called \textit{weak solution}. It can be shown, however, that even a simple case of a scalar conservation law may have multiple weak solutions. To select a "physically preferred" solution a concept of an "entropy function" $\eta$ is introduced. This is a special (convex) function that allows to symmetrizes the spatial Jacobian, $\nabla_{\boldsymbol{u}}f^i$. Together with the entropy flux, $\psi$, derived from compatibility relation, the $\eta\psi$ constitute and \textit{entropy pair}. Then, a weak solution for which the entropy pair exists and admits

\begin{equation}
\partial_t\eta(\boldsymbol{u}) + \nabla\cdot\boldsymbol{\psi}(\boldsymbol{u})\leq 0,
\label{eq:theory:nummeth:entropic}
\end{equation}

is the \textit{entropic solution}. The criterion can de understood, as requiring that the process, that led to the formation of a shock is irreversible \cite{LeVeque:1992}. In a scalar case $m=1$, the existence and uniqueness was shown possible for broad range of conditions \cite{Kruzkov:1970}. The extension to the  measure-valued solutions was stated by \cite{DiPerna:1985} and to the conservation laws on manifolds \cite{Benartzi:2007}. 

In case of a system of conservation laws, however, the existence of an entropy flux $\psi$ is not guaranteed and the uniqueness and stability of entropic solution has not been proven. 
Thus, while in one dimension and with a particular equation of state such properties can be found \textit{e.g.,} \cite{Chen:2009}, for a general equations the existence and uniqueness of the Reimann problem is not assured \cite{Curtis:1972}.

Another examples, of where the weak solution existence was found are the relativistic case \cite{Glimm:1965} with however ultrarelativistic equation of state only \cite{Smoller:1993} and strictly hyperbolic systems with a smooth enough initial conditions \cite{Lax:1957}.

For a recent review on the topic, see \textit{e.g.,} \cite{Chen:2006}. 

%%
%% []
%%

\subsection{Consistency, Stability and Convergence}

For the discussion of a numerical treatment of conservation laws, several key concepts ought be to be introduced. For simplicity, we limit ourselves to the $m=1$, one-dimensional case, where $\boldsymbol{u}$ of equation \ref{eq:theory:conservlaws} are scalar functions $u$. Let us further simplify notations, by viewing the solution to the 1D version of equation \ref{eq:theory:conservlaws} as a a function of time only $u(t)$, a bounded "curve" in infinite dimension vector space. Then, the \ref{eq:theory:conservlaws} can be viewed as an infinite system of ordinary differential equations (ODEs), written symbolically as

\begin{equation}
\frac{\text{d}u(t)}{\text{d}t} = \mathcal{L}[u(t)], \hspace{10mm} u(0) = u_0,
\label{eq:theory:conservlawsode}
\end{equation}

where we associate the operator $\mathcal{L}(\cdot)$ with the $-\nabla\cdot\boldsymbol{f}(\cdot)$. 
Importantly, the solution to \ref{eq:theory:conservlawsode} is not necessarily smooth in time and thus ought to be considered in terms of distributions. We however, assume for the purpose of this discussion that the $u(t)$ is a smooth function. In addition, by saying $u(0) = u_0$ we have broken a certain mathematical rigor. This is acceptable for our task, however, for more details we refer to the \cite{Kruzkov:1970}. 

Now we discuss the numerical approximation to \ref{eq:theory:conservlawsode}. This begins with introducing a discretization parameter $\Delta$ into the equation \ref{eq:theory:conservlawsode} such that $u^{\Delta}\approxeq u $, $L^{\Delta}\approxeq \mathcal{L}$ and $u^{\Delta}(0) \approx u_0$. In the latter, there is an additional error associated projection operator, but it is usually negligible in comparison with the one associated with discretization. One of these errors is the \textit{truncation error}, $r^{\Delta}$, which is due to approximating $\mathcal{L}[u(t)]$ with $L^{\Delta}[u(t)]$, where $u(t)$ is the exact solution to \ref{eq:theory:conservlaws}. A scheme is called \textit{consistent} if truncation error converges to zero as $\Delta \rightarrow 0$ in some (problem- and method dependent) norm for all possible initial data $u_0$. A scheme is said to be of order $r$ if $|| r^{\Delta}(t) || = \mathcal{O}(\Delta^r)$. A scheme is said to be \textit{stable} if this norm is limited $|||L^{\Delta}||| \leq C$, where $C\geq 0$ is a constant independent of $\upsilon$. And a scheme is said to be \textit{convergent} if a limit of $||u^{\Delta}(t)-u(t)|| = 0$ when $\Delta\rightarrow 0$. Lax-Richtmeyer equivalence for a linear equations state that numerical approximation of well-posed problems is convergent if and only if the scheme is stable and consistent \cite{Lax:1956}, thus relating consistency, stability and convergence. For a non-linear case a stronger criterion \textit{non-linear stability} is however required. 

%%
%%
%%

\subsection{Non-Linear Equations and Non-Linear Stability}

Up to this point we were focusing on the discretization of spatial derivatives of the ODE \ref{eq:theory:conservlawsode}, \textit{i.e.,} the operator $L^{\Delta}[u(t)]$, eluding mentioning the time discretization. The reason for that is an observation, that in the context of non-linear conservation laws, the former introduces a much larger error than the latter. However, for the discussion of non-linear stability and convergence, we must focus on both, introducing \textit{fully discrete} schemes.
In \cite{Kruzkov:1970}, it was shown, that there exist a one-parameter family of evolution operators $\{\mathcal{T}_{s\in\text{I\!R}_+}\}$. Its discrete from is $\{ T^{\Delta} _{k \Delta t} \}_{k\in\text{I\!N}}$ The $\mathcal{T}_t(u_0)$ yields a solution of \ref{eq:theory:conservlaws} at a time $t$, given the initial data $u_0$. Then, a scheme in its fully discrete form is $ u^{\Delta}(t+\Delta t) = T^{\Delta} _{\Delta t}[u^{\Delta}(t)]$. The choice of a single discretization parameter $\Delta$ is justified by the Courant-Friedrichs-Lewy (CFL) condition, which connects time and space discretization that preserve stability. 
In a fully discrete form, the consistency condition is $||\cdot||$, $||r^{\Delta}(t)||\rightarrow 0$ when $\Delta\rightarrow 0$ and linear stability requires $|||T^{\Delta}_{\Delta t}||| \leq C$ where $C$ is a constant. The Truncation error is $r^{\Delta}(t) = T^{\Delta}_{\Delta t}[u(t)] - \mathcal{T}_{\Delta t}[u(t)]$, where $u(t)$ is the exact solution to \ref{eq:theory:conservlaws}. 

%% on the TV stability

Now we proceed with outlying how a numerical scheme can be constructed in a non-linear case. We start with a fundamental Lax-Wendroff theorem, \cite{Lax:1960}, that states that for a function $u$ to be a weak solution of \ref{eq:theory:conservlaws}, the numerically approximated solution $u^{\Delta}$ to the \ref{eq:theory:conservlawsode} obtained via conservative and consistent scheme, should converge strongly. Hence, once the condition for a scheme to be convergent is found, the Lax-Wendroff theorem assures that solution obtained via such a scheme is weak solution\footnote{However, the solution is not guaranteed to be entropic. For that the scheme has to also satisfy the entropy inequality.}. 

A concept of convergence is related to a concept of bound variation (BV) invariance and compactness of bounded sets. The BV space is a space of all functions with finite total variation (TV) \cite{Luigi:2002}. It can be shown that if initial data belongs to a $\text{BV}(\text{I\!R}^d)$, then the solution $u \in \text{BV}(\text{I\!R}\times\text{I\!R}^d)$, for $t > 0$, $u(t) \in \text{BV}(\text{I\!R}^d)$, which constitutes the BV-invariance. This is however not necessarily the case for a system of cosnervation laws. See \textit{e.g.,} \cite{Chen:2006}. In addition, it can be shown that for a given set of functions that belongs to BV, there exists a subset converging in the $L^1$-norm to a specific function \cite{Luigi:2002}. 

Thus, if we have a numerical scheme that displays a behavior akin BV-invariance, the Lax-Wendroff Theorem assure that the it $L^1$ stable and consistent. Then, a solution obtained via such a scheme converges in $L^1$-norm to a weak solution as $\Delta\rightarrow 0$. Such a scheme is called \textit{TV-stable}. A particular class of schemes having this property is the \textit{total-variation diminishing} (TVD) schemes. 

Convergence in the case of non-linear conservation laws was first shown for \textit{monotone} schemes, for which if $u \geq \upsilon$ the $T_{s}^{\Delta}(u) \geq T_{s}^{\Delta}(\upsilon)$. A monotone and conservative $T_{s}^{\Delta}$ implies that it satisfies the strong stability condition \cite{Crandall:1980proc}, and that the method is TVD \cite{LeVeque:1992}. A numerical solution obtained via a consistent, stable and monotone scheme converges to a weak solution of \ref{eq:theory:conservlaws}, which is also entropic \cite{Crandall:1980}. However, an accuracy of a monotone scheme was shown to be limited to a first order \cite{Harten:1976}. 

An adaptive approach was employed to achieve higher accuracy, while preserving TVD properties in 1D\footnote{in the multi-dimensional case, TVD schemes are necessarily at most first-order accurate \cite{Goodman:1985}}, however at a loss of monotonicity. These methods are non-linear stable and high order accurate by allowing the order of convergence decrease to a first order in the vicinity of discontinuities. These are high resolution shock-capturing (HRSC) schemes. Contraction of a high order multidimensional schemes require weaker conditions of non-linear stability. A second-order central-scheme by Kurganov and Tadmor \cite{Kurganov:2000} is an example, of such a scheme, satisfying the maximum-principle. 

Owing to these complications, the most widely used numerical schemes are neither TVD nor have been shown to be TV stable. Moreover, in case of general systems of non-linear conservation laws, even the 1D stability and convergence has not been proven. Use of these schemes is advocated by numerical evidence of their convergence to an entropic solution. However, the mathematical proof remains to be provided, which in part requires better understand the characterization of entropic solutions \cite{Tadmor1998} and in part -- in properties of systems of conservation laws.  

%%
%%
%%

\subsection{Finite-Volume Methods}

Finite-volume methods are widely used in computational fluid dynamics \gray{owing to what?}. The Godunov scheme \cite{Godunov:1959} was the first such scheme able to yield solutions with discontinuities without spurious numerical extrema and with least numerical dissipation, \textit{i.e.,} being a \textit{monotonicity-preserving} scheme. There is a plethora of broadly used Godunov-type, methods for conservation laws, built on top of the original, see \textit{e.g.,} \cite{Toro:1999} for an up-to-date overview of the subject. 

In this subsection we outline the basic Godunov method for the first order schemes, and remark on the second-order Godunov-type schemes, most popular for relativistic hydrodynamic applications. We close the subsection mentioning the extension of FV methods to even higher orders, and difficulties involved to its application.

%%
%%
%%

\subsubsection{The Godunov Method}

We start by defining what is \textit{Reimann problem}. Reimann problem is a special initial value problem, that involve conservation equations and piece-wise constant initial data with a single discontinuity. Can naturally arise in FV methods due to discreteness of the grid. A \textit{Reimann solver} then is a special method to compute a numerical flux across a discontinuity in a Reimann problem. Mostly used in high order accuracy schemes. Left and right states usually evaluated using some form on non-linear reconstructor, which are then used as input for a Reimann solver. To reduce the computational cost, the iterative procedure is commonly replaced by approximations, such as Roe, HLLE, HLLC solvers. 

In his pioneer work, Godunov \cite{Godunov:1959} established main principles that most modern hock-capturing methods are based upon. Studying the linear-advection equation and assuming leanar scheme is to be used for discretization, he showed that all monotonicity-preserving are at most first-order accurate. It was pointed out later that nonlinear schemes are required to achieve higher-order accuracy \cite{Boris:1971,vanLeer:1973}. In addition, Godunov has shown first-order upwind algorithm is the most accurate monotonicity-preserving scheme for the advection equation, elaborating on how it can be extended to the non-linear case. 

We will restrict ourselves to a very brief description of an application of FV method to a one dimensional scalar hyperbolic advection equation 

\begin{equation}
    \partial_t u + \partial_x f(u) = 0.
    \label{eq:theory:fv:adveq}
\end{equation}

The equation \ref{eq:theory:fv:adveq} is to be case on a uniformly-spaced grids in space $ x_i = i\Delta^1$ and time $t_n = n\Delta^0$ where $n\in\mathbb{N}$. In the foundation of FV methods lie the control volumes, defined as $[x_{i-1/2},x_{i+1/2}]$, over which the average value of $u$ is $\bar{u}_i ^n$. \\
Averaging the avdection equation \ref{eq:theory:fv:adveq} over one control volume and one time-step we obtain

\begin{equation}
    \frac{\bar{u}_{i}^{n+1}-\bar{u}_{i}^{n}}{\Delta^0} = \frac{1}{\Delta^0}\int_{t_n}^{t_{n+1}}\big\{f[u(t,x_{i-1/2})] - f[u(t,x_{i+1/2})]\big\}\text{d}t
    \label{eq:theory:fv:intadveq}
\end{equation}

without making any approximation. To solve integrals on r.h.s of \ref{eq:theory:fv:intadveq} we need to solve Riemann problems centered at the interfaces between control-volumes. To obtain a solution at the time $n+1$, \textit{i.e.,} $\{U_{i}^{n+1}\}_{i\in\mathbb{Z}}$, starting from the solution at time $n$ \textit{i.e.,} $\{U_{i}^{n}\}_{i\in\mathbb{Z}} \approx \{\bar{u}_{i}^{n}\}_{i\in\mathbb{Z}}$, Godunov assumed that a solution can be represented as a \textit{piece-wise constant} in each control volume. The form of the solution is such that it is only non-zero within a given control volume. Then, as Riemann problems, required for r.h.s of \ref{eq:theory:fv:intadveq} are centered about interfaces between adjacent control-volumes, integral form of advection equation \ref{eq:theory:fv:intadveq} can be solved exactly for all $t\in[t_n, t_{n+1}]$. Provided, a sufficiently small time-step $\Delta^0$ is adopted that satisfies the CFL condition $\text{CFL} := \Delta^0 / \Delta^1 \leq c^{-1} $, where $c$ is the maximum propagation speed. Notably, obtaining $\{U^{n+1}_i\}_{i\in\mathbb{Z}}$ is further simplified as the $u(t, x_{i-1/2})$ is constant with time \cite{LeVeque:1992}.

A semi-discrete form of Godunov scheme \ref{eq:theory:fv:intadveq} can be written as 

\begin{equation}
\frac{\text{d}U_i}{\text{d} t} = \frac{1}{\Delta^1}[F(U_{i-1}, U_{i}) - F(U_i, U_{i+1})].
\label{eq:theory:fv:semi-discrete}
\end{equation}

where $F(U_{i-1}, U_{i})$ and $F(U_i, U_{i+1})$ are \textit{numerical fluxes} introduced on a premise that solution $u(t, x_{i-1/2})$ depends on $U_{i-1} ^n$ and $U_{i} ^n$ as $u(t, x_{1/2}) =: u^* (U_{i-1}^{n}, U_{i}^n)$. 

The introduction of semi-discrete formulations simplifies the discussion on high order FV schemes and on coupling between hydrodynamic equations and other systems of equations \textit{e.g.,} spacetime evolution, that are evolved with methods other then FV. Thus, we shall restrict ourselves to the discussion of FV methods in this form. We refer to \textit{e.g.,} \cite{Toro:1999} for a comprehensive description of FV methods and to \cite{Gassner:2011} for a more up-tp-date discussion regarding the higher order time discretization methods for FV. 

The extension of FV method in form \ref{eq:theory:fv:semi-discrete} to 3D,  $\boldsymbol{x}_{i,j,k} = (i\Delta^1,j\Delta^2,k\Delta^3)$ where $i, j, k \in \mathbb{Z}$ is simple and done via adding $F^1$, $F^2$ and $F^3$, numerical fluxes associated with $f^1$, $f^2$ and $f^3$ respectively. Similarly, by introducing a generic control-volume $\Omega_a$ and $\boldsymbol{\nu}$ is the inwards pointing normal to $\Omega$, the FV methods can be extended to a unstructured grid in multi-dimensions.  

A particular aspect of FV schemes, is that after the Reimann problem is solved at the interface between control-volumes, most of the information is lost in the subsequent averaging. Thus, even using approximate Reimann solvers, a monotone scheme can be obtained. It was shown to be particularly useful when Reimann problems are complex \textit{e.g.,} in relativistic Euler equation \cite{Marti:1994,Pons:2000,Giacomazzo:2005jy}. However, it also implies high diffusivity of FV schemes \cite{Harten:1983}. In most solvers, the numerical flux $F(U)$ is treated separately for left $U_L$ and right $U_R$ states. A popular examples or such solvers are HLLE solver \cite{Roe:1981}, the Marquina flux-formula \cite{Donat:1996} and HLLE solver \cite{Einfeldt:1988}. 

%%
%%
%%

\subsubsection{TVD Finite-Volume Methods}

The difficulty in constructing high order finite volume methods is the loss of information at the averaging step. However, this information can be recovered via \textit{reconstruction techniques} To suppress spurious oscillations from appearing and achieve high order accuracy, the non-linear reconstruction procedures of the solution $u$ are needed. The technique resembles linear regression. It relies on adopting the second order approximation of $u$ as $U_i(x) = U_i + \sigma_i(x-x_i)$, where $\sigma_i$ is the reconstructed slope in $[x_{i-1/2},x_{i+1/2}]$ and $U_i(x)$ is a profile of the solution $U$. As at the interface between control volumes, the profiles may not agree, the $U^{-}$ and $U^{+}$ are introduced into the FV scheme. Instantaneous fluxes then given by $F(U_L, U_R)$, which implies that the solution at the next time step depends only on the jump between two state $U_L$ and $U_R$. Hence, if a second order time integrator is used as well, the second order accuracy scheme is obtained \footnote{This is true in a semi-discrete form. In a fully discrete from, the use of predictor-corrector technique is required}. The choice of $\sigma_i$, that assures that the scheme is TV, is dictated by a special limiter \textit{slope-limiter}. Such are "minmod", "minmod2" limiters \cite{LeVeque:1992}, that reduce a scheme to the first order in the vicinity of discontinuities, preventing spurious oscillations. For a system of conservation laws, the reconstruction is usually done component-wise.

%%
%%
%%

\subsubsection{Higher-Order Finite-Volume Methods}

Via a technique similar to linear regression, we were able to extend the Godunov scheme to a second order. Employing a polynomial regression instead, higher order schemes can be constructed. Consider a generic function $\upsilon(x)$, its generic volume-average $\widetilde{\upsilon}_i$. To obtain a high-order approximation of $\upsilon$ at a point $x$ from $\widetilde{\upsilon}_i$ we employ a non-linear reconstruction operator $\mathcal{R}$. Owing to possible discontinuities, we actually use left-biased $\mathcal{R}^-$ and tight-biased $\mathcal{R}^+$. The operator is of order $r$. Its action on the average returns 
$\upsilon^{-}_{i+1/2}$ and $\upsilon^{+}_{i+1/2}$ respectively, high order approximations. Examples of $\mathcal{R}$ are: the piecewise parabolic method (PPM) \cite{Colella:1984,Colella:2008}, the piecewise hyperbolic method (PHM) \cite{Marquina:1994}, the essentially nonoscillatory (ENO) \cite{Harten:1987,Shu:1988,Shu:1989}, weighted essentially non-oscillatory (WENO) \cite{Liu:1994,Jiang:1996} and monotonicity-preserving (MP5) \cite{Suresh:1997} algorithms. 

In particular, the WENO scheme achieve high accuracy by combining results from multiple reconstructions. It takes a weighted average of the reconstructed polynomial on each stencil, suppressing the non-smooth stencils via small weights. As it does not use conditional statements to select the smoothest stencil as ENO does, it is more computationally efficient. However, at high orders it was shown to be unstable and requires additional limiting techniques \cite{Gerolymos:2009,Tchekhovskoy:2007zn,Balsara:2000}. See \textit{e.g.,} \cite{Gerolymos:2009} for implementation details of WENO scheme. For more advanced versions of WENO scheme, built to reduce numerical dissipation, see \cite{Martin:2006} and \cite{Taylor:2007}. 

The MP5 scheme is a 5th order method, that employs flattening, that reduces the effect of artificial extrema, via smoothing procedures. It is a monotonicity-preserving scheme, that does not introduce spurious oscillations, however, having many conditional statements in limiting procedures it is not as computationally efficient as WENO schemes.

%%
%%
%%

\subsubsection{Very-High-Order Finite-Volume Schemes}

Formally, in 1D the construction of high order schemes can be done via prescribing high order non-oscillatory reconstruction operators $\mathcal{R}$. However, as all of them fall to the first order in the vicinity of shocks, the actual accuracy is solution dependent. The main problem comes in composing a suitable quadrature formulas for $\mathcal{R}$ multidimensional case. Numerical tests also showed, that for a system of conservation laws in order to avoid spurious oscillations in the numerical solution, instead of component-wise reconstruction is disfavored, the local characteristic, conserved variables ought to be used. In case of a general relativistic hydrodynamics, the computational cost of using FV schemes is very high. The reason for that is the need to  compute metric source terms and interpolate the metric at the quadrature points with very high accuracy, as well as to compute fluxes. However, the superior accuracy of these methods assures their growing number of applications. \textit{e.g.,} \cite{Tchekhovskoy:2007zn,Dumbser:2007}.

%%
%THC actually has both FD and FV schemes implemented
%3:15
%FV is exactly conservative and there is a better way to do AMR with it
%3:16
%FD is better because it is much simpler at higher order
%3:16
%with THC when we want to do high order precision things we use FD
%3:16
%when we do messy simulations with microphysics, for which robustness and conservation are more important than formal order of convergence, we use FV
%3:17
%to be more precise we actually use the Kurganov-Tadmor central scheme, not a Godunov-type FV scheme
%3:17
%but people always mixes the two (see e.g., the discussion in my PhD thesis)
% So, our simulations with microphysical eos andneutrinos are performed using the KT FV scheme?
% yes KT FV
%%

\subsection{Central Methods}

Central schemes, introduced by Lax and Friedrichs (LxF) \cite{Lax:1954,Friedrichs:1954}, are schemes that do not requires Riemann solvers, contrary to the standard (upwind) finite volume schemes. They are simple in implementation, inexpensive computationally but highly dissipative numerically. Their higher order implementations include second order scheme by Nessyahu and Tadmor (NT) \cite{Nessyahu:1990} and further advancements done by Kurganov and Tadmor (KT) \cite{Kurganov:2000}. 

The key concept of the LxF scheme is the \textit{dual grid}, $\{x_{i+1/2}\}_{i\in\mathbb{Z}}$ (composed of centers), introduced into Godunov scheme. Hence, the name of the method. This grid is used to compute local averages, $\{U_{i}^{n}\}_{i\in \mathbb{Z}}$, of the solution, $U^n$, on the previous time step, $t_n$, to obtain a solution at the time $t_{n+1}$. The reason why we can avoid using Riemann solvers here is that the solution at cell centers remain free of discontinuities for the duration of a time step if the CFL $\leq 1/2 a$, where $a$ is the maximum local-characteristic speed. 

For a basic Godunov scheme, the piece-wise constant solution and reconstruction are employed, while for the second order, piecewise linear approximation and minmod reconstruction are used \cite{Nessyahu:1990}. The downside, however, is high, time-step dependent, numerical dissipation. It was addressed by Kurganov and Tadmor \cite{Kurganov:2000}, who introduces limiting technique for fluxes, Rusanov fluxes, that resembles the behavior of Riemann solvers, and assures the stability of the system when $1/2 < a \cdot \text{CFL} \leq 1$. This makes a distinction between modern FV and central schemes more phenomenological. 

%%
%%
%%

\subsection{Finite-Difference Methods}
\red{To be further shortened}

As an alternative to high order FV schemes, a new method was proposed, where the approximation is done point-wise instead of averaging over volumes \cite{Shu:1988,Shu:1989,Jiang:1996}. Finite-Difference (FD) methods perform better and especially efficient in multi-dimensional case with respect to high order FV schemes \cite{Shu:1999,Shu:2003}. The modern finite difference high resolution shock capturing schemes is a complicated topic that will only briefly discuss. We refer more more in-depth discussion to \cite{Shu:1999,Mignone:2010}.

Consider the system of hyperbolic balance-laws

\begin{equation}
\partial_t\boldsymbol{F}^0(\boldsymbol{u}) + \partial_i\boldsymbol{F}^i(\boldsymbol{u}) = \boldsymbol{S}(\boldsymbol{u}),
\label{eq:theory:fd:hypsys}
\end{equation}

and cast it on a Cartesian uniform spatial grid $ \boldsymbol{x}_{i,j,k} = (i\Delta^1, j\Delta^2, k\Delta^3) $ where $ i,j,k\in \mathbb{Z} $. To obtain a numerical approximation to the solution $u$, $u_{i,j,k}$ at a point $x_{i,j,k}$, we write the semi-discrete FD scheme, which in 3D consists of three terns of the form $(\boldsymbol{F}^{1}_{i-1/2,j,k} - \boldsymbol{F}^{1}_{i+1/2,j,k}) / \Delta^1$. However, while in FV schemes $\boldsymbol{F}$ are integrals of the control volumes along the boundary, in FD, they are direct (high-order, non-oscillatory) approximations of the point-wise value of $-\partial_1 F^1$ at a point $x_{i,j,k}$. Thus, at the second order the FD and FV schemes looks equivalent. The difference emerges at higher orders, where FD is more efficient and simpler, as it  does not require any quadrature, Riemann solvers or extra primitive recovery calls\footnote{As in high order finite volume schemes it is generally not possible to preserve higher order accuracy in conversion from volume-averaged conserved variables to volume-averaged primitive ones. The reconstruction have to be done in terms of the former}. FD methods are also more computationally favorable for GRHD, as the source term treatment is simpler. 

Consider the mechanism of FD scheme. For that we take a one-dimensional advection (hyperbolic, scalar) equation \ref{eq:theory:fv:adveq}. The core of FV method is to evaluate left, $U_L$, and right, $U_R$, states via reconstruction operator and then compute fluxes. In FD the reconstruction operators are used to obtain non-oscillatory approximation $\partial_x f$. For that a function $h(x)$ is introduced to represent the average between $x_{i+1/2}$ and $x_{i-1/2}$ as a value of $f$ at $x_i$ with no approximations \cite{Shu:1988}. Then the derivative approximation, $(\partial_{x} f)_{x_i} = [h(x_{i+1/2}) - h(x_{i-1/2}) ]/\Delta$, has an accuracy $r$, same, as the reconstruction operator $\mathcal{R}$ that was used to recover $h_{i+1/2}$. The stability of the scheme is assured by correctly "upwinding" the reconstruction separately for a left-going $f^{-}$ and right-going $f^{+}$, where the flux $f$ was split as $f = f^{+} + f^{-}$.

Then

\begin{equation}
\frac{\partial f(u)}{\partial x} = \frac{f_{i+1/2} - f_{i-1/2}}{\Delta} + \mathcal{O}(\Delta^r)
\end{equation}

yields the required high order approximation to $\partial_x$ at $x_i$. This. once again, resembles Riemann solver approach. 

There are several methods to split the flux $f$. In particular, \textit{Roe flux-split} and \textit{Rusanov flux-split} \cite{Shu:1997}. The former is more efficient. However, it can lead to odd-even decoupling phenomenon \cite{Quirk:1994} and, in presence of transonic refraction waves the Roe flux-splitter may result in the formation of entropy-violating shocks \cite{LeVeque:1992}. See \cite{LeVeque:1992,Radice:2012cu} for more discussion on these issues.

In case of a general system of conservation laws \ref{eq:theory:fd:hypsys}, spatial derivatives can be evaluated via a component-by-component approach via methods outlined above. This is sufficient for a second order schemes, to achieve higher order, reconstruction is to be done on local characteristic variables of the system. Constructing a Jacobian matrices $\boldsymbol{A}^{\alpha} = \partial \boldsymbol{F}^{\alpha} / \bar{\boldsymbol{u}}$ where $\alpha = 0,1$, and inverting them\footnote{As the \ref{eq:theory:fd:hypsys} is strongly hyperbolic, the matrix $\boldsymbol{A}^0$ can be inverted.}, solving the generalized eigenvalue problem, we obtain only real eigenvalues $\lambda_{(I)}$ and $N$ real, independent, right-eigenvectors, $r_{(I)}$ [see, \textit{e.g.,} \cite{Anile:1990}]. Then we construct matrix of eigenvectors be $R$ and $L$ its inverse and obtain local characteristic variables $\omega = Lu$ and $Q = LF^1 $. Which we use to reconstruct $F$ as $F^1_{i+1/2, j, k} = RQ_{i+1/2, j, k}$. \red{Results shown in this thesis are obtained, via reconstraction of local charactersitic variables. Sure?}. 

The downside to the FD schemes is their reliance on Cartesian grids (uniform or with Berger-Oliger-style AMR \cite{Berger:1984}). In case of cell-centered AMR with refluxing, \cite{Berger:1989}, the FD scheme reduce to second order at the boundary of refinement levels.

%%
%%
%%

\subsection{Discontinuous Galerkin Methods}

Proposed by Reed and Hill \cite{Reed:1973} for hyperbolic equations, and further developed in  \cite{Cockburn:1991,Cockburn:1989ii,Cockburn:1989iii,Cockburn:1990iv,Cockburn:1998v}, the Discontinuous Galerkin (DG) Methods has been growing in popularity and numer of applications ever since. The extension of the method to elliptic and parabolic equations \cite{Arnold:2002} have further solidified this trend \cite{Cockburn:2000,Canuto:2008,Hesthaven:2007}. The method was applied to Einstein system of equations in vacuum \cite{Field:2010} and to general-relativistic hydrodynamics \cite{Radice:2011qr}. The reason for such attention, is the sheer number of proven numerical properties, such as intrinsic non-linear stability at any accuracy order\footnote{For that, however, the limiters and/ro filtering are required for the treatment of under-resolved parts inf the solution, \textit{i.e.,} shocks. In case of truncation expansion poorly capturing the solution behavior, the aliasing instabilities occur and nonphysical modes introduced into the solution, leading to non-linear instabilities \cite{Boyd:2001}}, assurance of cell-entropy inequality, \textit{i.e.,} the solution is always entropic achieving high, spectral accuracy in smooth regions \cite{Cockburn:2003}, and in certain cases, assurance of maximum-principle \cite{Zhang:2011}. DG schemes, (and finite-element method, FEM)  are also covariant, independent of a coordinate system chosen, which makes them of particular interest for general relativity applications \cite{Meier:1999}. For transport problems, where physical dissipation is important, DG methods are of special importance as well, as for a smooth solution they allow for practically no numerical dissipation \cite{Cockburn:2003}. Ability to use unstructured grids and achievable efficiency of DG methods makes them very promising for massive parallel applications \cite{Biswas:1994}. 
The downside of DG methods are the larger memory requirements with respect to FV/FD methods. In addition, if a solution exhibits discontinuities, special techniques to reduce oscillations are required, that do not hinder the scheme accuracy. It was also shown that the linear stability requires more stringent CFL condition. To address that, novel hybrid DG-FV scheme were proposed \cite{Qiu:2005,Qiu:2004} and \cite{Dumbser:2009,Dumbser:2008} with somewhat different approach. For recent advances in this scheme applications see \textit{e.g.,} \cite{Gassner:2011} and \cite{Hesthaven:2007}.

%%
%%
%%

\subsubsection{Runge-Kutta Discontinuous-Galerkin Methods}

Let us consider widely used variant of DG method, spectral discontinuous Galerkin methid with numerical integration (SDGM-NI) \cite{Hesthaven:2007}, as an example of how DG methods work. For the purpose of being brief, we focus on na advection equation with no sources \textit{i.e.,} $\partial_t + \nabla\cdot\boldsymbol{f}(u) =0$ where $(t,x)\in \text{I\!R}_{+} \times\Omega$, with $\Omega\subset \text{I\!R}^{d}$ being a bounded, regular domain. The core idea behind DG methods is to perform a triangulation $\mathbb{T}$, such that the domain, $\Omega$, dissolves into $N$ images of a reference element, $T$, \textit{i.e.,} $\cup_{j=1}^{N}\Omega_{j} = \Omega$ and $\Omega_{i}\cap\Omega_{j} = \emptyset$. These elements are usually a triangles in 2D and tetrahedrons in 3D. The created mapping allows to "pull-back" the equations from a given element that has an arbitrary complexity in physical space, into a reference one, in which all discrete derivatives, interpolation and integration have been already pre-computed a simple geometry. In addition, in relativistic case, a covariance of the scheme can be "combined" with the covariance of equations to render the scheme effectively coordinate-free. 

A classical approach to construct a weak formulation of the scheme for an advection equation, is related to the concept of bound variation. Thus, we assume that $u$ is supposedly a bounded function in space and smooth function of time and introduce a smooth test function $\upsilon \in C_0 ^1(\Omega)$ as following

\begin{equation}
    \sum_{j=1}^{N}\Bigg[\int_{\Omega_j}\partial_{t}u\upsilon\text{d}x - \int_{\Omega_j}\boldsymbol{f}(u)\cdot\nabla\upsilon\text{d}x\Bigg] = -\sum_{j=1}^{N}\langle\boldsymbol{\mathcal{F}}\cdot\boldsymbol{\nu},\upsilon\rangle_{\partial\Omega_j}.
    \label{eq:theory:dg:intformadveq}
\end{equation}

where $\boldsymbol{\mathcal{F}}\cdot\boldsymbol{\nu}$ is the normal trace of $\boldsymbol{f}(u)$ on the boundary.

Then, obtaining a weak formulation narrows down to getting $u\in\text{BV}(\Omega)$ such that equation \ref{eq:theory:dg:intformadveq} holds for any $\upsilon \in C_0 ^1(\Omega)$. This is accomplished by projecting $u\in\text{BV}(\Omega)$ on a finite-dimensional subspace of BV$(\Omega)$ by introducing a piecewise polynomial function on $\mathcal{T}_{N}$

\begin{equation}
V_N = \big\{ \upsilon\in\text{BV}(\Omega):\upsilon\circ\phi\in\text{I\!P}_{D}(T), \: j=1,...,N \big\}
\label{eq:theory:dg:weakforkreq}
\end{equation}

where $\text{I\!P}_{D}$ is the space of polynomials of degree $D$. And then the obtained a weak formulation further narrows down to finding $u(t) = C^1(\text{I\!R}_{+};v_N)$ such that for any $ \upsilon\in V_N $ the equation \ref{eq:theory:dg:intformadveq} holds. Note that $V_N$ continuity of functions in was not required in \ref{eq:theory:dg:weakforkreq}. Also, in our formulation test function and numerical solution $u$ belong to the same functional space. This is the origin of the scheme name \textit{discontinuous Galerkin}. Finally, the degrees of freedom of $u$ are obtained from conditions that arise when equation \ref{eq:theory:dg:intformadveq} in considered for a large but finite number of linearly independent test functions $\upsilon$. 

Next, starting from \ref{eq:theory:dg:intformadveq} we construct the general from of a DG scheme in one-dimensional case. We do so by introducing $F$, numerical fluxes similarly as to how it was done for finite volume methods and perform an expansion of $F$ on a polynomial basis $l_{i}^{j}$ over $[x_{j-1/2}, x_{j+1/2}]$. Then we chose $l_{k}^{j}$ that yield set of evolution equations for the expansion coefficients, which in more compact form read

\begin{equation}
\boldsymbol{M}^{j} - \boldsymbol{D}^{j}\boldsymbol{f} = \boldsymbol{F}^{j-1/2} - \boldsymbol{F}^{j+1/2}, \hspace{5mm} \text{for any } j=1,...,N \\
\end{equation}

where $u^{j}$ contain all the expansion coefficients $u$,  $\big(\boldsymbol{M}^j\big)_{ki}$ is the mass matrix, defined on a single element and in most cases can be diagonalized \cite{Canuto:2008}, $\big(\boldsymbol{D}^{j}\big)_{ki}$ is the co-differential matrix, for which inadequately chosen quadrature can violate non-linear stability \cite{Hesthaven:2007}, and $\big(F^{j-1/2}\big)_i$ are the flux vectors. \textcolor{gray}{see more in chapter 6}



% References
%%
%% ---------------

\newpage

\bibliography{../references}


\end{document}
